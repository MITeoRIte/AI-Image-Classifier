{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating two directories - \"data\" and \"data/trainset_11classes_0_00000\" \n",
    "# !mkdir data && mkdir data/trainset_11classes_0_00000\n",
    "# Downloading the ai-camp competition dataset\n",
    "# !wget -N https://ai-camp.s3-us-west-2.amazonaws.com/trainset_11classes_0_00000.zip\n",
    "# !wget -N https://ai-camp.s3-us-west-2.amazonaws.com/trainset_4classes_2_20406.zip\n",
    "# Unzip the data into the folder \"data/trainset_11classes_0_00000\"\n",
    "# !unzip -qq -n trainset_4classes_2_20406.zip -d data/trainset_11classes_0_00000\n",
    "# Switch directory to \"data/trainset_11classes_0_00000\" and show its content\n",
    "# !cd data/trainset_11classes_0_00000 && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "base_dir = 'data/trainset_11classes_0_00000'\n",
    "\n",
    "# Directory to our training data\n",
    "train_folder = os.path.join(base_dir, 'train')\n",
    "\n",
    "# Directory to our validation data\n",
    "val_folder = os.path.join(base_dir, 'val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# List folders and number of files\n",
    "# print(\"Directory, Number of files\")\n",
    "# for root, subdirs, files in os.walk(base_dir):\n",
    "#     print(root, len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /home/ec2-user/.local/lib/python3.6/site-packages (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/ec2-user/.local/lib/python3.6/site-packages (from keras) (1.16.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3.6/dist-packages (from keras) (1.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/lib64/python3.6/dist-packages (from keras) (1.2.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ec2-user/.local/lib/python3.6/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in /usr/lib64/python3.6/dist-packages (from keras) (3.13)\n",
      "Requirement already satisfied: h5py in /home/ec2-user/.local/lib/python3.6/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/ec2-user/.local/lib/python3.6/site-packages (from keras) (1.0.8)\n",
      "\u001b[33mYou are using pip version 19.0.2, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install keras --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing generator for train dataset\n",
      "Found 1322 images belonging to 15 classes.\n",
      "Preparing generator for validation dataset\n",
      "Found 347 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Batch size\n",
    "bs = 32 \n",
    "\n",
    "# All images will be resized to this value\n",
    "image_size = (299, 299)\n",
    "\n",
    "# All images will be rescaled by 1./255. We apply data augmentation here.\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   brightness_range= [0.5,1.5],\n",
    "                                   horizontal_flip=True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "print(\"Preparing generator for train dataset\")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory= train_folder, # This is the source directory for training images \n",
    "    target_size=image_size, # All images will be resized to value set in image_size\n",
    "    batch_size=bs,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Flow validation images in batches of 32 using val_datagen generator\n",
    "print(\"Preparing generator for validation dataset\")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    directory= val_folder, \n",
    "    target_size=image_size,\n",
    "    batch_size=bs,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.applications.xception import Xception\n",
    "from keras.layers import Input, Conv2D, BatchNormalization, Activation, GlobalAveragePooling2D, Dense, Dropout, MaxPooling2D, Flatten\n",
    "\n",
    "keras.layers.ZeroPadding2D(padding=(1, 1), data_format=None)\n",
    "\n",
    "# Here we specify the input shape of our data \n",
    "# This should match the size of images ('image_size') along with the number of channels (3)\n",
    "input_shape = (299, 299, 3)\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 15\n",
    "# keras.applications.xception.Xception(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "\n",
    "# Defining a baseline model. Here we use the [keras functional api](https://keras.io/getting-started/functional-api-guide) to build the model. \n",
    "# TODO: explore different architectures and training schemes\n",
    "base_model = Xception(include_top=False, weights='imagenet', input_shape=(299,299,3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model= Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dense(15,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 10, 10, 2048)      20861480  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 204800)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              209716224 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 15)                15375     \n",
      "=================================================================\n",
      "Total params: 231,642,679\n",
      "Trainable params: 210,781,199\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from adabound import AdaBound\n",
    "\n",
    "\n",
    "# optm = AdaBound(lr=1e-03,\n",
    "#                 final_lr=0.1,\n",
    "#                 gamma=1e-03,\n",
    "#                 weight_decay=0.,\n",
    "#                 amsbound=False)\n",
    "optm = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True) #might be effective, interrupted too soon\n",
    "optm = optimizers.Adam(lr=0.01, epsilon=None, decay=0.0)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optm,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#learning rate in adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "bestValidationCheckpointer = ModelCheckpoint('train_model.hdf5', monitor='val_acc', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "39/42 [==========================>...] - ETA: 42s - loss: 14.6789 - acc: 0.0689"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "        train_generator, # train generator has 973 train images\n",
    "        steps_per_epoch=train_generator.samples // bs + 1,\n",
    "        epochs=30,\n",
    "        validation_data=val_generator, # validation generator has 253 validation images\n",
    "        validation_steps=val_generator.samples // bs + 1,\n",
    "        callbacks=[bestValidationCheckpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_path = 'saved_model.hdf5'\n",
    "model = load_model( model_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator.reset()\n",
    "\n",
    "scores = model.evaluate_generator(val_generator, steps=val_generator.samples // val_generator.batch_size + 1, verbose=1)\n",
    "print('Val loss:', scores[0])\n",
    "print('Val accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
